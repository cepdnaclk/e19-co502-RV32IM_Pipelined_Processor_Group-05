    # x4 = 0x00012345
    lui  x4, 0x00012        # x4 = 0x00012000
    addi x4, x4, 0x345      # x4 = x4 + 0x345 = 0x00012345

    # x5 = 0x000AB7F  (use 0xB7F = 2943, within range)
    lui  x5, 0x000AB        # x5 = 0x000AB000
    addi x5, x5, 0x7F       # x5 = 0x000AB07F
    addi x5, x5, 0x100      # x5 = 0x000AB17F
    addi x5, x5, 0x200      # x5 = 0x000AB37F

    # x6 = 0x00F00001
    lui  x6, 0x00F00        # x6 = 0x00F00000
    addi x6, x6, 0x001      # x6 = x6 + 1 = 0x00F00001

    # x7 = 0xFFFFF800 (negative offset using -2048)
    lui  x7, 0xFFFFF        # x7 = 0xFFFFF000
    addi x7, x7, -2048      # x7 = 0xFFFFF800

    # x8 = 0x80000000 (just load upper)
    lui  x8, 0x80000        # x8 = 0x80000000
    addi x8, x8, 0          # x8 = 0x80000000

    # x9 = 0x00000000 (build 0 using +0x1000 and -0x1000 as two steps within range)
    lui  x9, 0x00001        # x9 = 0x00001000
    addi x9, x9, -0x800     # x9 = 0x00000800
    addi x9, x9, -0x800     # x9 = 0x00000000
